{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2><center><font color='black'>   Keeping up with the Deep-Learning Curve via Keras </font></center></h2>\n",
    "\n",
    "<img src='imgs/front_3.png' align='middle'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/neuron_test.png' align='middle'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/neural_score.png' align='middle'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src='imgs/lin_class.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/softmax.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/linear_2.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/mnist_wt.png' align='middle'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'>  XOR Example </font></center></h4>\n",
    "<img src='imgs/xor_test.png' align='middle'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'>  XOR Transformed </font></center></h4>\n",
    "<img src='imgs/xor_trans.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'>Convex Cost Function </font></center></h4>\n",
    "\n",
    "<img src='imgs/convex_new1.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'>Non-Convex Cost Function </font></center></h4>\n",
    "\n",
    "<img src='imgs/non_convex.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<img src='imgs/backprop_clean.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/cnn_1.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/cnn_3.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'>AlexNet </font></center></h4>\n",
    "\n",
    "<img src='imgs/alex3.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'> Convolutional Layer </font></center></h4>\n",
    "\n",
    "<img src='imgs/3D_Convolution_Animation.gif'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'>Our 96 Filters </font></center></h4>\n",
    "<img src='imgs/gabor1.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'> Max-Pooling Layer </font></center></h4>\n",
    "<img src='imgs/max_pool.png'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><center><font color='#F87217'>Final Layers  </font></center></h4>\n",
    "<img src='imgs/more_filters.png'/>\n",
    "\n",
    "Credits: [Yosinski](http://yosinski.com)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center><font color='#F87217'> KERAS  </font></center></h1>\n",
    "\n",
    "<h4><center><font color='black'> High-Level Deep Learning Library for Theano & Tensorflow  </font></center></h4>\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keras was developed to allow for fast and easy deep-learning prototyping through the use of: \n",
    "  - user friendliness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Keras was developed to allow for fast and easy deep-learning prototyping through the use of: \n",
    " - user-friendliness\n",
    " - modularity\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Keras was developed to allow for fast deep-learning prototyping through the use of: \n",
    " - user-friendliness\n",
    " - modularity\n",
    " - extensibility\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed()\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, ZeroPadding2D, Conv2D, MaxPooling2D, Flatten, Dropout, LSTM\n",
    "from keras.layers import Embedding, Input \n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils.vis_utils import model_to_dot, plot_model\n",
    "\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.6'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "data=pd.DataFrame(X)\n",
    "data['target']=y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "data['name']=data.target.astype('str').replace({'0':'setosa','1':'versicolor','2':'virginica'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12196ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAHUCAYAAAAZcrFFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAA1vkPa3UHHkZqA1MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121953da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ax=subplot(1,1,1)\n",
    "\n",
    "#plt.scatter(data[0],data[1], c=data.target)\n",
    "plt.figure(figsize=(10,7))\n",
    "ax=data.plot(kind='scatter',x=0,y=1,c='target',legend=False,figsize=(12,8))\n",
    "plt.xlabel('sepal length')\n",
    "plt.ylabel('sepal width')\n",
    "plt.title('Iris Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#  Define our first Model.. \n",
    "\n",
    "model=Sequential()\n",
    "# output will be number of classes, and input will be # of features\n",
    "model.add(Dense(units=3,input_dim=4))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"215pt\" viewBox=\"0.00 0.00 300.56 215.00\" width=\"301pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 211)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-211 296.5557,-211 296.5557,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4861446744 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4861446744</title>\n",
       "<polygon fill=\"none\" points=\"0,-162.5 0,-206.5 292.5557,-206.5 292.5557,-162.5 0,-162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-180.3\">dense_2_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"167.2383,-162.5 167.2383,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.0728\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167.2383,-184.5 222.9072,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.0728\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.9072,-162.5 222.9072,-206.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.7314\" y=\"-191.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"222.9072,-184.5 292.5557,-184.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.7314\" y=\"-169.3\">(None, 4)</text>\n",
       "</g>\n",
       "<!-- 4861549424 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4861549424</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-81.5 31.4932,-125.5 261.0625,-125.5 261.0625,-81.5 31.4932,-81.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-99.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135.7451,-81.5 135.7451,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5796\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135.7451,-103.5 191.4141,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5796\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191.4141,-81.5 191.4141,-125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-110.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"191.4141,-103.5 261.0625,-103.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.2383\" y=\"-88.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 4861446744&#45;&gt;4861549424 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4861446744-&gt;4861549424</title>\n",
       "<path d=\"M146.2778,-162.3664C146.2778,-154.1516 146.2778,-144.6579 146.2778,-135.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"149.7779,-135.6068 146.2778,-125.6068 142.7779,-135.6069 149.7779,-135.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4861532816 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4861532816</title>\n",
       "<polygon fill=\"none\" points=\"8.1587,-.5 8.1587,-44.5 284.397,-44.5 284.397,-.5 8.1587,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-18.3\">activation_2: Activation</text>\n",
       "<polyline fill=\"none\" points=\"159.0796,-.5 159.0796,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.9141\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159.0796,-22.5 214.7485,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.9141\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"214.7485,-.5 214.7485,-44.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5728\" y=\"-29.3\">(None, 3)</text>\n",
       "<polyline fill=\"none\" points=\"214.7485,-22.5 284.397,-22.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5728\" y=\"-7.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 4861549424&#45;&gt;4861532816 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4861549424-&gt;4861532816</title>\n",
       "<path d=\"M146.2778,-81.3664C146.2778,-73.1516 146.2778,-63.6579 146.2778,-54.7252\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"149.7779,-54.6068 146.2778,-44.6068 142.7779,-54.6069 149.7779,-54.6068\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output from previous layer --> input to the next layer \n",
    "SVG(model_to_dot(model,show_shapes=True).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s - loss: 0.8112 - acc: 0.5800 - val_loss: 0.6458 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: 0.7418 - acc: 0.6500 - val_loss: 0.5713 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: 0.6129 - acc: 0.8600 - val_loss: 0.5917 - val_acc: 0.7200\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: 0.6171 - acc: 0.7300 - val_loss: 0.5141 - val_acc: 0.9800\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: 0.5505 - acc: 0.8700 - val_loss: 0.4939 - val_acc: 0.9200\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: 0.5309 - acc: 0.9600 - val_loss: 0.4627 - val_acc: 0.9200\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: 0.5095 - acc: 0.8300 - val_loss: 0.4592 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: 0.5020 - acc: 0.9500 - val_loss: 0.4439 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: 0.4829 - acc: 0.9200 - val_loss: 0.4232 - val_acc: 0.7800\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: 0.4886 - acc: 0.6900 - val_loss: 0.4359 - val_acc: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x111b094d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y=to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "np.random.ran\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,nb_epoch=10,validation_data=(X_test,y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"215pt\" viewBox=\"0.00 0.00 300.56 215.00\" width=\"301pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 211)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-211 296.556,-211 296.556,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4595205648 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4595205648</title>\n",
       "<polygon fill=\"none\" points=\"0,-162.5 0,-206.5 292.556,-206.5 292.556,-162.5 0,-162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-180.3\">dense_input_2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"167.238,-162.5 167.238,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.073\" y=\"-191.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167.238,-184.5 222.907,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"195.073\" y=\"-169.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222.907,-162.5 222.907,-206.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.731\" y=\"-191.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"222.907,-184.5 292.556,-184.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"257.731\" y=\"-169.3\">(None, 4)</text>\n",
       "</g>\n",
       "<!-- 4595205392 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4595205392</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-81.5 31.4932,-125.5 261.062,-125.5 261.062,-81.5 31.4932,-81.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-99.3\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"135.745,-81.5 135.745,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.58\" y=\"-110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"135.745,-103.5 191.414,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.58\" y=\"-88.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"191.414,-81.5 191.414,-125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.238\" y=\"-110.3\">(None, 4)</text>\n",
       "<polyline fill=\"none\" points=\"191.414,-103.5 261.062,-103.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"226.238\" y=\"-88.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 4595205648&#45;&gt;4595205392 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4595205648-&gt;4595205392</title>\n",
       "<path d=\"M146.278,-162.329C146.278,-154.183 146.278,-144.699 146.278,-135.797\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"149.778,-135.729 146.278,-125.729 142.778,-135.729 149.778,-135.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4595205520 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4595205520</title>\n",
       "<polygon fill=\"none\" points=\"8.15869,-0.5 8.15869,-44.5 284.397,-44.5 284.397,-0.5 8.15869,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-18.3\">activation_2: Activation</text>\n",
       "<polyline fill=\"none\" points=\"159.08,-0.5 159.08,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.914\" y=\"-29.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159.08,-22.5 214.749,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.914\" y=\"-7.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"214.749,-0.5 214.749,-44.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.573\" y=\"-29.3\">(None, 3)</text>\n",
       "<polyline fill=\"none\" points=\"214.749,-22.5 284.397,-22.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.573\" y=\"-7.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 4595205392&#45;&gt;4595205520 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4595205392-&gt;4595205520</title>\n",
       "<path d=\"M146.278,-81.3294C146.278,-73.1826 146.278,-63.6991 146.278,-54.7971\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"149.778,-54.729 146.278,-44.729 142.778,-54.729 149.778,-54.729\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, what did we do ?\n",
    "\n",
    "model=Sequential()\n",
    "# output will be number of classes, and input will be # of features\n",
    "model.add(Dense(output_dim=3,input_dim=4))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "SVG(model_to_dot(model,show_shapes=True).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's build the model again.. \n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(output_dim=64,input_dim=4))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=32))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=3))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 0s - loss: 1.6446 - acc: 0.3400 - val_loss: 1.1870 - val_acc: 0.3200\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: 1.0819 - acc: 0.3000 - val_loss: 0.7880 - val_acc: 0.7000\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: 0.8199 - acc: 0.6100 - val_loss: 0.6959 - val_acc: 0.7000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: 0.7034 - acc: 0.7600 - val_loss: 0.8422 - val_acc: 0.6800\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: 0.7657 - acc: 0.5900 - val_loss: 0.5462 - val_acc: 0.7000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: 0.6023 - acc: 0.6300 - val_loss: 0.3986 - val_acc: 0.8600\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: 0.4317 - acc: 0.8700 - val_loss: 0.3400 - val_acc: 0.9800\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: 0.3724 - acc: 0.9600 - val_loss: 0.3064 - val_acc: 0.9600\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: 0.3703 - acc: 0.8900 - val_loss: 0.2971 - val_acc: 0.8800\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: 0.3447 - acc: 0.8900 - val_loss: 0.2560 - val_acc: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1127ea4d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "# adding early stopping \n",
    "my_callback=keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "model.fit(X_train,y_train,nb_epoch=10,validation_data=(X_test,y_test),batch_size=32,callbacks=[my_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  What can be gained by making the network wider & deeper?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "###  What can be gained by making the network wider & deeper?   \n",
    "\n",
    " -  A sufficiently wide neural net can approximate any function (given enough training data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  What can be gained by making the network wider & deeper?   \n",
    "\n",
    " -  A sufficiently wide neural net can approximate any reasonable function (however.. )\n",
    " -  A deep network can be quite good at generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  And now,  CNN in Keras! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Macroarchitecture of VGG16\n",
    "<img src='imgs/VGG.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.utils.np_utils import convert_kernel\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 31675  100 31675    0     0  17326      0  0:00:01  0:00:01 --:--:-- 17327\n"
     ]
    }
   ],
   "source": [
    "# get labels\n",
    "!curl https://raw.githubusercontent.com/torch/tutorials/master/7_imagenet_classification/synset_words.txt -o synset_words.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download weights from [here](https://github.com/fchollet/deep-learning-models/releases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = VGG_16('/Users/julialintern/Downloads/vgg16_weights.h5')\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synset = pd.read_csv('synset_words.txt', skipinitialspace=True, names = ['synset', 'words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    im = cv2.resize(cv2.imread(image_path), (224, 224)).astype(np.float32)\n",
    "\n",
    "    im[:,:,0] -= 103.939\n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/sloth.jpg'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968\n",
      "n07930864 cup\n"
     ]
    }
   ],
   "source": [
    "img = prepare_image('sloth.jpg')\n",
    "out = model.predict(img)\n",
    "y_pred = np.argmax(out)\n",
    "\n",
    "print y_pred\n",
    "print synset.loc[y_pred].synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Nets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src='imgs/fc_piece.png'/>\n",
    "<img src='imgs/rnn3.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LSTM  - Long Short Term Memory\n",
    "\n",
    "<img src='imgs/lstm_3_anno.png'/>\n",
    "<img src='imgs/lstm_eqn.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  375542\n",
      "Total Vocab:  50\n"
     ]
    }
   ],
   "source": [
    "# load text & convert to lower case..\n",
    "# You can load this from nltk_data/corpora\n",
    "my_file='shakespeare-caesar.txt'\n",
    "file_1='shakespeare-hamlet.txt'\n",
    "file_2='shakespeare-macbeth.txt'\n",
    "\n",
    "my_text=open(my_file).read()\n",
    "my_one=open(file_1).read()\n",
    "my_two=open(file_2).read()\n",
    "\n",
    "alls=my_text+my_one+my_two\n",
    "my_text=alls.lower()\n",
    "\n",
    "\n",
    "# TODO : redo in pandas\n",
    "#Create a mapping of unique Characters to integers\n",
    "chars = sorted(list(set(my_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "n_chars = len(my_text)\n",
    "vocab = len(chars)\n",
    "\n",
    "print \"Total Characters: \", n_chars\n",
    "print \"Total Vocab: \", vocab\n",
    "# prepare the dataset of input to output pairs encoded as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb sequences:', 125174)\n"
     ]
    }
   ],
   "source": [
    "# Developing our input & output: \n",
    "\n",
    "max_len = 20\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(my_text) - max_len, step):\n",
    "    sentences.append(text[i: i + max_len])\n",
    "    next_chars.append(text[i + max_len])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization..\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization..')\n",
    "X=np.zeros((len(sentences),max_len,vocab))\n",
    "y=np.zeros((len(sentences),vocab))\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# use 'fast_compile' for more specific error traceback\n",
    "import theano\n",
    "theano.config.optimizer='fast_compile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125174/125174 [==============================] - 122s - loss: 2.0816   \n",
      "Epoch 2/10\n",
      "125174/125174 [==============================] - 128s - loss: 1.7153   \n",
      "Epoch 3/10\n",
      "125174/125174 [==============================] - 127s - loss: 1.6100   \n",
      "Epoch 4/10\n",
      "125174/125174 [==============================] - 126s - loss: 1.5481   \n",
      "Epoch 5/10\n",
      "125174/125174 [==============================] - 127s - loss: 1.5078   \n",
      "Epoch 6/10\n",
      "125174/125174 [==============================] - 129s - loss: 1.4777   \n",
      "Epoch 7/10\n",
      "125174/125174 [==============================] - 130s - loss: 1.4521   \n",
      "Epoch 8/10\n",
      "125174/125174 [==============================] - 130s - loss: 1.4319   \n",
      "Epoch 9/10\n",
      "125174/125174 [==============================] - 128s - loss: 1.4113   \n",
      "Epoch 10/10\n",
      "125174/125174 [==============================] - 145s - loss: 1.4026   \n"
     ]
    }
   ],
   "source": [
    "# OUR MODEL;\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(LSTM(128,input_shape=(max_length, vocab)))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "model.fit(X, y, batch_size=128, nb_epoch=10)\n",
    "\n",
    "model.save_weights('model_save.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('----- diversity:', 0.2)\n",
      "----- Generating with seed: \"friends, romans, cou\"\n",
      "\n",
      "\n",
      "friends, romans, countrymen,\n",
      "and stand to the countrymen,\n",
      "and the sayes the part he beare the countrymen,\n",
      "and the perule man in the countrymen,\n",
      "and stand all the strange of the deed,\n",
      "and the peese and country\n",
      "\n",
      "   ham. why the play a hamber of the country\n",
      "a countronce in the countrymen,\n",
      "and the words of the countrymen,\n",
      "and the strange of the more a come to the countrymen,\n",
      "and in the more the country\n",
      "a hand of the coun\n",
      "\n",
      "\n",
      "\n",
      "('----- diversity:', 0.5)\n",
      "----- Generating with seed: \"friends, romans, cou\"\n",
      "\n",
      "\n",
      "friends, romans, countrymen,\n",
      "and but the streat a soule,\n",
      "i will see you speake, but what shall lead the conish deer'd to speakes walke, and by valius of all stand of flay:\n",
      "i haue do you stay the pointly steele,\n",
      "and the terre haue giuen,\n",
      "and still not for this bleade you liue him are how thou haue a most seene the calle,\n",
      "and stand might and burse that of the canglesse,\n",
      "all the sold come of my friend, and bleed in the \n",
      "\n",
      "\n",
      "\n",
      "('----- diversity:', 1.0)\n",
      "----- Generating with seed: \"friends, romans, cou\"\n",
      "\n",
      "\n",
      "friends, romans, could, th' euen on mee:\n",
      "thus, the vilias kilds,\n",
      "need iutimeting stand he lady,\n",
      "to kell come here desire? is the heauens marnculit, and cupers free of fure, macbeth times terce budane,\n",
      "destru'd, we preat poyell too, for the mo: as entlere: posoyss'sty albouryce no my father,\n",
      "\n",
      "  ancarw a giuens he alt:\n",
      "this's giue stayre? ane very sucting free; speake with then come fro in take\n",
      "om that strop'd to messe\n",
      "\n",
      "\n",
      "\n",
      "('----- diversity:', 1.2)\n",
      "----- Generating with seed: \"friends, romans, cou\"\n",
      "\n",
      "\n",
      "friends, romans, coulders:\n",
      "hamlet,\n",
      "to tree; dirrbe reeay\n",
      "lyeng,  ours, i had not, that pit,\n",
      "fare'l,\n",
      "'tis boy or o'ctiyro: he wilt, thee feeme for?\n",
      "  ham. this keaue?\n",
      "  kin. goodnamorr, ayre, thatke, that awa't\n",
      "as is noclet of there, sirs, need\n",
      "\n",
      "   eon. shatmins, god. octruilulion,\n",
      "rihing badne nor. let an while wiuers, begwind.\n",
      "enter.\n",
      "\n",
      "munees to nature.\n",
      "thou heere thussueth all notspoke,\n",
      "it doth was asaid, what lree \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed='Friends, Romans, countrymen, lend me your ears'\n",
    "# Subset of seed, because we need to maintain length of 20 as input\n",
    "true_seed=seed[:20].lower()\n",
    "\n",
    "\n",
    "\n",
    "# As we increase the 'temperature', we see that the text generation becomes less predictable\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    #print()\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = ''\n",
    "    #sentence = my_text[start_index: start_index + max_length]\n",
    "    sentence= true_seed\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    print('\\n')\n",
    "    \n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(400):\n",
    "        x = np.zeros((1, max_length, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = int_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print('\\n'*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explorations  in Keras : Deep-Fashion\n",
    "<img src='imgs/deep_fashion.png'/>\n",
    "\n",
    "[DeepFashion: Powering Robust Clothes Recognition and Retrieval\n",
    "with Rich Annotations, Liu et al]('http://www.ee.cuhk.edu.hk/~xgwang/papers/liuLQWTcvpr16.pdf')\n",
    "\n",
    "- Liu et al, Chinese University of Hong Kong\n",
    "- 800 K images: annotated \n",
    "- FashionNet: learns clothing features by jointly predicting on attributes and landmarks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FashionNet nutshell : \n",
    " - Inputs: regional input (for this ex: upper body clothes)\n",
    " - Predictions :  attributes (ex: abstract floral print) , categories (top, dress..) , clothing landmarks, and landmark visibility\n",
    "- Essentially the left lower branch is based off VGG 16.. we will modify the architecture from there.\n",
    "     \n",
    "     \n",
    "\n",
    "<img src='imgs/landmarks.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julialintern/anaconda/envs/ipython_env/lib/python3.5/site-packages/keras/applications/vgg16.py:181: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "vgg16 = VGG16(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SVG(model_to_dot(vgg16,show_shapes=True).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze layers before the 5th conv. block\n",
    "for layer in vgg16.layers[:14]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab output directly after last conv layer\n",
    "\n",
    "convs = vgg16.get_layer('flatten').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# pick up where that left off. . \n",
    "#create new layers\n",
    "new = Dense(4096, activation='relu', name='fc6_pose')(convs)\n",
    "new = Dense(4096, activation='relu', name='fc7_pose')(new)\n",
    "\n",
    "# predict locations\n",
    "\n",
    "# output : 2 visibility probabilities\n",
    "vis1 = Dense(2, activation='softmax', name='visibility1')(new)\n",
    "vis2 = Dense(2, activation='softmax', name='visibility2')(new)\n",
    "vis3 = Dense(2, activation='softmax', name='visibility3')(new)\n",
    "vis4 = Dense(2, activation='softmax', name='visibility4')(new)\n",
    "vis5 = Dense(2, activation='softmax', name='visibility5')(new)\n",
    "vis6 = Dense(2, activation='softmax', name='visibility6')(new)\n",
    "\n",
    "# landmark outputs\n",
    "lm=Dense(12,activation='linear',name='landmarks')(new)\n",
    "\n",
    "outputs=[vis1, vis2, vis3, vis4,vis5, vis6, lm]\n",
    "\n",
    "model = Model(input=vgg16.input, output=outputs)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can create our own custom loss functions in Keras.. \n",
    "\n",
    "\n",
    "def custom_objective(y_true, y_pred):\n",
    "    '''tailored cost function'''\n",
    "    \n",
    "    #get landmarks\n",
    "\n",
    "    pred_lm=y_pred[6]\n",
    "    true_lm=y_true[6]\n",
    "    \n",
    "    pred_lm=K.reshape(pred_lm,(6,2))\n",
    "    true_lm=K.reshape(true_lm,(6,2))\n",
    "    \n",
    "    # get visibility binaries\n",
    "    true_viz=y_true[:6]\n",
    "    \n",
    "    # predict if visible or not, if not visible, set landmark loss to zero\n",
    "    wins=K.argmax(true_viz,axis=1)\n",
    "    \n",
    "    #shapes : wins: (1,6), pred_lm: 6,2\n",
    "    loss=K.mean(K.square(K.dot(wins,(pred_lm-true_lm))))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Assign specific loss functions, metrics & weights to specific outputs.. \n",
    "\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "losses={'visibility1':'binary_crossentropy','visibility2':'binary_crossentropy','visibility3':'binary_crossentropy',\n",
    "        'visibility4':'binary_crossentropy','visibility5':'binary_crossentropy',\n",
    "'visibility6':'binary_crossentropy', 'landmarks':custom_objective}\n",
    "\n",
    "my_metrics={'visibility1':single_class_accuracy(0),'visibility2':single_class_accuracy(0),'visibility3':single_class_accuracy(0),\n",
    "        'visibility4':single_class_accuracy(0),'visibility5':single_class_accuracy(0),\n",
    "'visibility6':single_class_accuracy(0),'landmarks':'mean_squared_error'}\n",
    "\n",
    "adam=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss=losses,optimizer=adam,metrics=my_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "filepath='weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "mcp=keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "callback=[mcp]\n",
    "test=model.fit_generator(train_flow_from_directory(train_generator, train_lab_1,train_lab_2,train_lab_3,train_lab_4,train_lab_5,train_lab_6, lm_train_labels),\\\n",
    "                         validation_data=test_flow_from_directory(test_generator, test_lab_1,test_lab_2,test_lab_3,test_lab_4,test_lab_5,test_lab_6,\\\n",
    "                                                                  lm_test_labels),\n",
    "                         nb_epoch=20,samples_per_epoch=20000, nb_val_samples=5000,callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/dress_two.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "####  A Different type of Style Transer !\n",
    "<img src='imgs/final_both.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='imgs/thanks.png'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
